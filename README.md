# Langchain

A comprehensive Python-based repository to explore, prototype, and experiment with LangChain concepts, including LLMs, embeddings, retrieval-augmented generation (RAG), chains, output parsers, and Streamlit-based chatbot interfaces. This project serves as a modular sandbox for experimenting with LangChain features, agent tools, and modern retrieval architectures.

---

## ğŸš€ Project Overview

This project demonstrates an end-to-end framework for building, running, and testing various LangChain pipelines and concepts. It covers:

- Large Language Models (LLMs)
- Embedded Models
- Retrieval-Augmented Generation (RAG)
- Runnable patterns (Passthrough, Sequence, Parallel)
- Chains (conditional, sequential, parallel)
- Output parsers with Pydantic schemas
- Streamlit-based user interfaces
- Chat model integrations (OpenAI, Hugging Face, Claude, etc.)

The repository is modular, making it easy to extend, plug in new models, and explore LangChain use cases with a clear directory structure.

---

## ğŸ“ Folder Structure

```text
Langchain/
â”œâ”€â”€ EmbeddedModels/
â”‚   â”œâ”€â”€ hugging_face1.py
â”‚   â”œâ”€â”€ huginf_face_local.py
â”‚   â”œâ”€â”€ open_ai_doc.py
â”‚   â””â”€â”€ open_ai.py
â”œâ”€â”€ LLMs/
â”‚   â””â”€â”€ llm_demo.py
â”œâ”€â”€ Rags/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â””â”€â”€ tools.py
â”‚   â”œâ”€â”€ document_loader/
â”‚   â”‚   â”œâ”€â”€ business.txt
â”‚   â”‚   â”œâ”€â”€ directory_loader.py
â”‚   â”‚   â”œâ”€â”€ Hessian_Examples.pdf
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”‚   â”œâ”€â”€ text_loader.py
â”‚   â”‚   â”œâ”€â”€ web_base_loader.py
â”‚   â”‚   â””â”€â”€ wikipedia.cpython-312.pyc
â”‚   â”œâ”€â”€ Retrivers/
â”‚   â”‚   â””â”€â”€ __pycache__/
â”‚   â”œâ”€â”€ Text_splitter/
â”‚   â”‚   â”œâ”€â”€ code_splitter.py
â”‚   â”‚   â”œâ”€â”€ length_based.py
â”‚   â”‚   â”œâ”€â”€ length_bases_pdf.py
â”‚   â”‚   â”œâ”€â”€ markdown_splitter.py
â”‚   â”‚   â””â”€â”€ text_based.py
â”‚   â”œâ”€â”€ Youtube_chatbot.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Runnable/
â”‚   â”œâ”€â”€ Runnable.py
â”‚   â”œâ”€â”€ Runnable_passthrough.py
â”‚   â”œâ”€â”€ Runnable_parallel.py
â”‚   â””â”€â”€ Runnable_sequence.py
â”œâ”€â”€ Streamelit/
â”‚   â”œâ”€â”€ chatbot_command.py
â”‚   â”œâ”€â”€ chatbot_st.py
â”‚   â”œâ”€â”€ prompt_dynamic_minmax_2.py
â”‚   â”œâ”€â”€ prompt_dynamic_minmax.py
â”‚   â”œâ”€â”€ prompt_meloni.py
â”‚   â””â”€â”€ prompt_minmax.py
â”œâ”€â”€ chains/
â”‚   â”œâ”€â”€ conditional_chain.py
â”‚   â”œâ”€â”€ parallel_chain.py
â”‚   â””â”€â”€ seq_chain.py
â”œâ”€â”€ chatModels/
â”‚   â”œâ”€â”€ chat_model_claud.py
â”‚   â”œâ”€â”€ chat_model_google.py
â”‚   â”œâ”€â”€ chat_model_hugging_face_local.py
â”‚   â”œâ”€â”€ chat_model_hugging_face.py
â”‚   â””â”€â”€ chat_model_openai.py
â”œâ”€â”€ output_parsers/
â”‚   â”œâ”€â”€ string_output_json_chain.py
â”‚   â”œâ”€â”€ string_output_json.py
â”‚   â”œâ”€â”€ string_output_openai.py
â”‚   â”œâ”€â”€ string_output_parser_chain.py
â”‚   â”œâ”€â”€ string_output_parsers.py
â”‚   â”œâ”€â”€ string_pydantic_output.py
â”‚   â”œâ”€â”€ string_str_output_json_chain.py
â”‚   â””â”€â”€ string_structured_output.py
â”œâ”€â”€ structured_output/
â”‚   â”œâ”€â”€ json_str.json
â”‚   â”œâ”€â”€ pydantic_demo.py
â”‚   â”œâ”€â”€ str_output_dict.py
â”‚   â””â”€â”€ structured_output.py
â”œâ”€â”€ .env
â”œâ”€â”€ req.txt
â””â”€â”€ README.md


## ğŸ“‚ Folder Explanations

- **EmbeddedModels/**: Contains scripts to work with embedding models like Hugging Face and OpenAI.  
- **LLMs/**: Demonstrations of prompt-based LLM interactions.  
- **Rags/**: Retrieval-Augmented Generation modules including agents, document loaders, text splitters, retrievers, and YouTube chatbot examples.  
- **Runnable/**: Runnable patterns for chaining and controlling LLM operations.  
- **Streamelit/**: Streamlit-based chat interfaces and prompt experiments.  
- **chains/**: Conditional, parallel, and sequential chain orchestration examples.  
- **chatModels/**: Integration scripts for various chat providers (OpenAI, Claude, Hugging Face, Google).  
- **output_parsers/**: Includes pydantic-based and JSON-based parsing for LLM outputs.  
- **structured_output/**: Examples of structured output management, including Pydantic and JSON serialization.  
- **.env**: Environment variables file (add your own keys here, do not commit to GitHub).  
- **req.txt**: Lists the Python dependencies to install.  

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/vishalgwu/Langchain.git
cd Langchain

## Create a virtual environment-
python -m venv venv

## Activate the environment

On Windows:venv\Scripts\activate

On macOS/Linux:

bash
source venv/bin/activate

Install dependencies:
pip install -r req.txt

## API Keys & Environment Variables-
Copy the .env file provided, or create your own .env file in the root of the project.

Add your own API keys and secrets to the .env file, for example:
OPENAI_API_KEY=your_openai_api_key
HUGGINGFACE_API_KEY=your_huggingface_api_key
